{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e248b04-3a76-4ad0-833f-40eec10e3639",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b56eb486-1809-45a3-9c7c-0dd2005e7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# For Logistic Regression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For DistilBERT\n",
    "from datasets import Dataset\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "149f8586-8f53-49cb-8e39-908853274962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom functions\n",
    "from functions import load_parquet_as_df, is_sensitive, get_keywords_from_xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa015adc-58e3-4a9a-a080-5ec28bd34d32",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a3b1244-8d96-4c4b-89da-244300c3f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Outdated code, other data source used\n",
    "if 1 == 2:\n",
    "    # Adjust paths accordingly:\n",
    "    #test_path = \"data/OHSUMED/test-00000-of-00001.parquet\"\n",
    "    #train_path = \"data/OHSUMED/train-00000-of-00001.parquet\"\n",
    "\n",
    "    #import pandas as pd\n",
    "\n",
    "    splits = {'train': 'ohsumed/train-00000-of-00001.parquet', 'test': 'ohsumed/test-00000-of-00001.parquet'}\n",
    "    df_train = pd.read_parquet(\"hf://datasets/community-datasets/ohsumed/\" + splits[\"train\"])\n",
    "    df_test = pd.read_parquet(\"hf://datasets/community-datasets/ohsumed/\" + splits[\"test\"])\n",
    "\n",
    "    #df_test = load_parquet_as_df(test_path)\n",
    "    #df_train = load_parquet_as_df(train_path)\n",
    "\n",
    "    df_1 = pd.concat([df_test, df_train], axis=0)\n",
    "    print(df_1.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d514c34a-337e-484a-a8d3-755ce4d2f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outdated\n",
    "if 1 == 2:\n",
    "    print(len(df_1))\n",
    "    df_1.columns\n",
    "    print(df_1.info())\n",
    "    #display(df_1)\n",
    "    display(df_1[df_1[\"medline_ui\"] == 91343590])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0b7d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ohsumed_file(path: str):\n",
    "\n",
    "    # Initialisiere Variablen f√ºr den Datensatz\n",
    "    records = []\n",
    "    current_record = {}\n",
    "\n",
    "    # Datei zeilenweise einlesen\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip() \n",
    "            if line.startswith('.I'):  # Each Dataset starts with .I\n",
    "                if current_record:  #if there is a dataset allready, save it\n",
    "                    records.append(current_record)\n",
    "                current_record = {'Sequatial identifier': line.split(' ')[1]}  #initilize new dataset\n",
    "            else:\n",
    "                match line[:2]:  # first two chars decide which info is parsed\n",
    "                    case '.U':\n",
    "                        current_record['Medline ID'] = next(file).strip()\n",
    "                    case '.S':\n",
    "                        current_record['Source'] = next(file).strip()\n",
    "                    case '.M':\n",
    "                        current_record['mesh_terms'] = next(file).strip()\n",
    "                    case '.T':\n",
    "                        current_record['Title'] = next(file).strip()\n",
    "                    case '.P':\n",
    "                        current_record['Publication type'] = next(file).strip()\n",
    "                    case '.A':\n",
    "                        current_record['Author'] = next(file).strip()\n",
    "                    case '.W':\n",
    "                        current_record['Abstract'] = next(file).strip()\n",
    "        if current_record:\n",
    "            records.append(current_record)\n",
    "\n",
    "    # convert to df\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    #cast columns (maybe unnecessary)\n",
    "    df['Medline ID'] = df['Medline ID'].astype(int)\n",
    "    df['mesh_terms'] = df['mesh_terms'].astype(object)\n",
    "\n",
    "    return df.set_index(\"Medline ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8da13039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data is stored in 5 files\n",
    "files = [\"ohsumed.87.txt\", \"ohsumed.88.txt\", \"ohsumed.89.txt\", \"ohsumed.90.txt\",\"ohsumed.91.txt\"]\n",
    "#parses first file and converts it to a df\n",
    "df2= parse_ohsumed_file(files[0])\n",
    "#parses the rest of the files an concats them\n",
    "for file in files[1::]:\n",
    "    df2 = pd.concat([df2, parse_ohsumed_file(file)])\n",
    "#print(df2.info())\n",
    "#display(df2[df2[\"mesh_terms\"].isnull()])\n",
    "\n",
    "#fills na values\n",
    "df2[\"mesh_terms\"] = df2[\"mesh_terms\"].fillna(\"\")\n",
    "df2[\"Author\"] = df2[\"Author\"].fillna(\"\")\n",
    "df2[\"Abstract\"] = df2[\"Abstract\"].fillna(\"\")\n",
    "\n",
    "#print(df2.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b600fa9",
   "metadata": {},
   "source": [
    "# Relevance Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d881206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_judged_data(path:str):\n",
    "\n",
    "    df = pd.read_csv(path, sep=\"\\t\", header=None, names=[\"query\", \"Medline ID\", \"document-i\", \"relevance1\", \"relevance2\", \"relevance3\"])\n",
    "    #if in one of the 3 relevance couluns is a p (partly relevant) or d (definitely relevant), the document is labled as relavant (1) in a new relevance column\n",
    "    df[\"relevance\"] = df[[\"relevance1\", \"relevance2\", \"relevance3\"]].apply(\n",
    "    lambda row: 1 if any(val in ['p', 'd'] for val in row.fillna(0)) else 0,\n",
    "    axis=1\n",
    "    )\n",
    "    df = df.drop([\"relevance1\", \"relevance2\", \"relevance3\"], axis=1)\n",
    "    df['Medline ID'] = df['Medline ID'].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a76faa6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>Medline ID</th>\n",
       "      <th>document-i</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>87097544</td>\n",
       "      <td>40626</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>87153566</td>\n",
       "      <td>11852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>87157536</td>\n",
       "      <td>12693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>87157537</td>\n",
       "      <td>12694</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>87184723</td>\n",
       "      <td>15450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16135</th>\n",
       "      <td>106</td>\n",
       "      <td>91354564</td>\n",
       "      <td>337888</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16136</th>\n",
       "      <td>106</td>\n",
       "      <td>91354570</td>\n",
       "      <td>348231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16137</th>\n",
       "      <td>106</td>\n",
       "      <td>91356830</td>\n",
       "      <td>338251</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16138</th>\n",
       "      <td>106</td>\n",
       "      <td>91359739</td>\n",
       "      <td>338619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16139</th>\n",
       "      <td>106</td>\n",
       "      <td>91366431</td>\n",
       "      <td>339568</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16140 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       query  Medline ID  document-i  relevance\n",
       "0          1    87097544       40626          1\n",
       "1          1    87153566       11852          0\n",
       "2          1    87157536       12693          1\n",
       "3          1    87157537       12694          1\n",
       "4          1    87184723       15450          0\n",
       "...      ...         ...         ...        ...\n",
       "16135    106    91354564      337888          1\n",
       "16136    106    91354570      348231          0\n",
       "16137    106    91356830      338251          0\n",
       "16138    106    91359739      338619          0\n",
       "16139    106    91366431      339568          0\n",
       "\n",
       "[16140 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_judged = parse_judged_data(\"judged.txt\").drop_duplicates()\n",
    "display(df_judged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50baa34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>Medline ID</th>\n",
       "      <th>document-i</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>3</td>\n",
       "      <td>91374975</td>\n",
       "      <td>348498</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7545</th>\n",
       "      <td>53</td>\n",
       "      <td>91374975</td>\n",
       "      <td>348498</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018</th>\n",
       "      <td>37</td>\n",
       "      <td>91347198</td>\n",
       "      <td>348095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12596</th>\n",
       "      <td>83</td>\n",
       "      <td>91347198</td>\n",
       "      <td>348095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>14</td>\n",
       "      <td>91309028</td>\n",
       "      <td>347515</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15063</th>\n",
       "      <td>100</td>\n",
       "      <td>87058652</td>\n",
       "      <td>1136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11709</th>\n",
       "      <td>79</td>\n",
       "      <td>87055358</td>\n",
       "      <td>685</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>38</td>\n",
       "      <td>87055358</td>\n",
       "      <td>685</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5247</th>\n",
       "      <td>40</td>\n",
       "      <td>87051269</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5826</th>\n",
       "      <td>44</td>\n",
       "      <td>87051269</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       query  Medline ID  document-i  relevance\n",
       "525        3    91374975      348498          1\n",
       "7545      53    91374975      348498          1\n",
       "5018      37    91347198      348095          0\n",
       "12596     83    91347198      348095          0\n",
       "1504      14    91309028      347515          0\n",
       "...      ...         ...         ...        ...\n",
       "15063    100    87058652        1136          0\n",
       "11709     79    87055358         685          1\n",
       "5021      38    87055358         685          0\n",
       "5247      40    87051269         300          0\n",
       "5826      44    87051269         300          0\n",
       "\n",
       "[3200 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14430\n"
     ]
    }
   ],
   "source": [
    "#print(len(df_judged.drop([\"query\"], axis = 1).drop_duplicates()))\n",
    "df_judged = df_judged[df_judged[\"relevance\"] > -1]\n",
    "#display(df_judged[df_judged[\"document-i\"].duplicated() ==1])\n",
    "\n",
    "#remove duplicats in df_judged. if the duplicates relevance is judged diffrently, keep the one judged as relevent\n",
    "duplicates = df_judged[df_judged['document-i'].duplicated(keep=False)].sort_values(by=[\"document-i\", \"relevance\"], ascending=False)\n",
    "\n",
    "current_id = -1\n",
    "for i, rows in duplicates.iterrows():\n",
    "    if rows[\"document-i\"] == current_id:\n",
    "        df_judged =df_judged.drop(i)\n",
    "    else:\n",
    "        current_id = rows[\"document-i\"]\n",
    "display(duplicates)\n",
    "print(len(df_judged))\n",
    "# in paper just 4837 judged as relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b813285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join Ohsumed and judged df\n",
    "df_data = pd.merge(df2, df_judged[['Medline ID', 'relevance']], on='Medline ID', how='left')\n",
    "df_data[\"relevance\"] = df_data[\"relevance\"].fillna(-1)\n",
    "\n",
    "#outdated\n",
    "if 1 == 2:\n",
    "    #join Ohsumed data from Source 1 with juded df\n",
    "    df_1 = df_1.rename(columns={\"medline_ui\": \"Medline ID\"})\n",
    "    df_1 = pd.merge(df_1, df_judged[['Medline ID', 'relevance']], on='Medline ID', how='left')\n",
    "    df_1[\"relevance\"] = df_1[\"relevance\"].fillna(0)\n",
    "    #train / test split\n",
    "    df_1_test = df_1[df_1[\"relevance\"] == 1]\n",
    "    df_1_train = df_1[df_1[\"relevance\"] == 0]\n",
    "\n",
    "#split at later place\n",
    "#df_test = df_combined_2[df_combined_2[\"relevance\"] == 1]\n",
    "#df_train = df_combined_2[df_combined_2[\"relevance\"] == 0]\n",
    "#print(len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf6c11e-1015-4a93-b04b-672cd0fb457b",
   "metadata": {},
   "source": [
    "**View an example mesh_terms entry**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e81af1f-6275-4214-8e1b-cde0f5cb4dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Blood Pressure; Catheters, Indwelling/*ST; Hemodialysis/*ST; Human; Kidney Failure, Acute/*PP/TH; Kidney Failure, Chronic/*PP/TH; Polyurethanes; Quality Control; Support, Non-U.S. Gov't.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set max column width to display long strings fully\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Now, accessing the entry will show the full string\n",
    "df_data['mesh_terms'][92]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127f2d7b-9749-41c9-a947-7fbb8f744151",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Sensitivity Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "462394e8-e6f3-471a-b5e5-2f712a044a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "#MESH_XML_FILE = \"data/nlm/mesh/medit/ascii_xml/output/desc2022.xml\"\n",
    "#MESH_XML_FILE = \"desc2022/usr/nlm/mesh/medit/ascii_xml/output/desc2022.xml\"\n",
    "MESH_XML_FILE = \"desc2019.xml\"\n",
    "#MESH_XML_FILE = \"desc2022.xml\"\n",
    "\n",
    "c12_terms, c13_terms = get_keywords_from_xml(MESH_XML_FILE)\n",
    "print(c12_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dc44a26-9c84-4061-8c7c-13d9ee71fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary label based on if a match can be found\n",
    "df_data['sensitive_label'] = df_data['mesh_terms'].apply(\n",
    "    lambda x: is_sensitive(x, c12_terms, c13_terms)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72c5b611-9765-4555-9125-7b69cb47cf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00% of the rows are sensitive\n"
     ]
    }
   ],
   "source": [
    "percentage_sensitive = 100 * df_data['sensitive_label'].mean()\n",
    "print(f\"{percentage_sensitive:.2f}% of the rows are sensitive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7301a7ba-3082-4619-953f-279e05aa570b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd8dbe9c-5cc7-4b87-b68e-ca1a55c8f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only save relevant columns to make file smaller\n",
    "relevant_columns = ['Title', 'Abstract', 'sensitive_label',\"relevance\"]\n",
    "df_data = df_data[relevant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0ebcf09-b769-40f3-94a5-397f8b255f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv = False  # Set this to True if you want to save the current df\n",
    "\n",
    "if save_csv:\n",
    "    save_path = \"data/OHSUMED/full_ohsumed_sensitivity_labeled.csv\"\n",
    "    \n",
    "    # Check if the file already exists\n",
    "    if not os.path.exists(save_path):\n",
    "        df_1_train.to_csv(save_path, index=False)\n",
    "        print(f\"File saved to {save_path}\")\n",
    "    else:\n",
    "        print(f\"File already exists at {save_path}, skipping save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34f8da5c-82a7-458e-89fc-d670578fd461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine title and abstract\n",
    "df_data['text'] = df_data['Title'] + \" \" + df_data['Abstract']\n",
    "\n",
    "df_data = df_data[['text', 'sensitive_label', \"relevance\"]]  # we only need these three columns for the ML part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54775bc4-9436-4494-b113-e52a512f0d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A list which contains indices of rows which have a 1 as label\n",
    "# We can use it to find records which have been labeled as sensitive\n",
    "indices = df_data.index[df_data['sensitive_label'] == 1].tolist()\n",
    "indices[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79ccfb30-5c0d-4be3-86c5-1d6788a47947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sensitive_label</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Development of a small caliber vascular graft by a new crosslinking method incorporating slow heparin release collagen and natural tissue compliance.</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Strontium overload in uremic patients on regular dialytic treatment.</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                      text  \\\n",
       "23  Development of a small caliber vascular graft by a new crosslinking method incorporating slow heparin release collagen and natural tissue compliance.    \n",
       "24                                                                                   Strontium overload in uremic patients on regular dialytic treatment.    \n",
       "\n",
       "    sensitive_label  relevance  \n",
       "23                0       -1.0  \n",
       "24                0       -1.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of two rows, one from each group\n",
    "row_selection = df_data.iloc[23:25]\n",
    "row_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4b244b6-d76a-4935-8bfd-10d84e042017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14430\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "\n",
    "#test data is all data judged as relevant, rest is train data\n",
    "data_test = df_data[df_data[\"relevance\"] >-1]\n",
    "data_train =df_data[df_data[\"relevance\"] == -1]\n",
    "data_train = data_train.drop([\"relevance\"], axis=1)\n",
    "print(len(data_test))\n",
    "#split text and label of test data\n",
    "test_texts = data_test[\"text\"]\n",
    "test_labels = data_test[\"sensitive_label\"]\n",
    "\n",
    "\n",
    "#15% of the training data is used for validation\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    data_train[\"text\"], data_train[\"sensitive_label\"], test_size=0.85, random_state=123, stratify=data_train[\"sensitive_label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50484b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_texts))\n",
    "print(test_texts.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625bb793-ab54-4d90-b1f5-af3bf325c9dc",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "For the following, there was little information in the paper. We made basic assumptions on how to implement the LR. While not mentioned in the paper, TF-IDF is commonly used for obtaining features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7cc09-8005-4e5e-be8b-ee24e8a3fc80",
   "metadata": {},
   "source": [
    "**Note: the following cell typically takes a few minutes to run.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8652f30c-0e9e-4188-96b7-a4d1b13a90d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to numerical features using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2), stop_words='english')\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_val = vectorizer.transform(val_texts)\n",
    "X_test = vectorizer.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed559404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2c8d508-bd1a-4a69-8128-3aafe41a4e64",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the logistic regression model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:1301\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1299\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1301\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1305\u001b[0m     )\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1308\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "# Train the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=123)\n",
    "model.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6d4f142-dbc4-4eb0-83be-c3768868afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probabilities for the validation set\n",
    "val_probs = model.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc53276-1c12-4d66-b0ac-22f5a548d08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\larsb\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# As mentioned in the paper, use \"a grid search in the range [0, 1] with step size 0.01 to find the threshold that optimized the F1 measure.\n",
    "\n",
    "thresholds = np.linspace(0, 1, 101)\n",
    "best_threshold = 0\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in thresholds:\n",
    "    val_preds = (val_probs >= threshold).astype(int)\n",
    "    _, _, f1, _ = precision_recall_fscore_support(val_labels, val_preds, average='binary')\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"Optimal Threshold: {best_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c7bfac-7cf9-474f-8e17-5540c7bb0df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrinsic sensitivity classification results:\n",
      "Results of our code: Precision: 0.74, Recall: 0.70, F1: 0.72, F2: 0.70, Accuracy: 0.93\n",
      "Results in the paper: Presision: 76.72, Recall: 73.29, F1 74.96, F2: 73.95, Accuracy 94.01\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test set using the optimal threshold\n",
    "test_probs = model.predict_proba(X_test)[:, 1]\n",
    "test_preds = (test_probs >= best_threshold).astype(int)\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(test_labels, test_preds, average='binary')\n",
    "accuracy = accuracy_score(test_labels, test_preds)\n",
    "\n",
    "# Calculate F2 score\n",
    "f2 = fbeta_score(test_labels, test_preds, beta=2, average='binary')\n",
    "\n",
    "print(\"Intrinsic sensitivity classification results:\")\n",
    "print(f\"Results of our code: Precision: {precision:.2f}, Recall: {recall:.2f}, F1: {f1:.2f}, F2: {f2:.2f}, Accuracy: {accuracy:.2f}\")\n",
    "print(\"Results in the paper: Presision: 76.72, Recall: 73.29, F1 74.96, F2: 73.95, Accuracy 94.01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3051a243",
   "metadata": {},
   "source": [
    "![alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65452189-af42-41f3-8aa7-9863270e4e1f",
   "metadata": {},
   "source": [
    "# DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee5da657-25f9-4647-bfc5-21808bc46fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "train_data = Dataset.from_dict({\"text\": train_texts, \"label\": train_labels})\n",
    "val_data = Dataset.from_dict({\"text\": val_texts, \"label\": val_labels})\n",
    "test_data = Dataset.from_dict({\"text\": test_texts, \"label\": test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c89226b-ac0e-4422-b117-deb95c475155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heavily shorten the training data for now, otherwise model training takes forever\n",
    "n = 50\n",
    "v = 10\n",
    "t = 10\n",
    "train_data = train_data.select(range(n))  # only take first n rows\n",
    "val_data = val_data.select(range(v))\n",
    "test_data = test_data.select(range(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ae2236-b97a-4d39-8ed9-21595e01af84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT is ready!\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "print(\"DistilBERT is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd78683-b265-4154-871d-3791d361b085",
   "metadata": {},
   "source": [
    "**Note: the following cell typically takes a few minutes to run.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c46b266-a843-46f3-83cf-b8b7ac24f448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c23e7f9a2646a6be5e5397b0f42e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed9125df87f4370860a3c8a6ae0d293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b531cedd30d4915993f03a2775f78fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize data\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "train_data = train_data.map(tokenize_function, batched=True)\n",
    "val_data = val_data.map(tokenize_function, batched=True)\n",
    "test_data = test_data.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b19ea3a-1678-4dfc-9aa9-839e4c68703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data format for PyTorch\n",
    "train_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "val_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b89198-af91-4dca-8c37-70c25d2ca083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda3f745-6346-4157-b7d5-42288dd6d18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\larsb\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28df8ca4-ba07-4350-ba7a-e36823d36e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb97026-3e70-4fa4-a73b-6effdde4eea7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2/12 : < :, Epoch 0.25/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\trainer.py:2531\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2524\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2525\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2528\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2529\u001b[0m )\n\u001b[0;32m   2530\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2531\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2534\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2535\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2537\u001b[0m ):\n\u001b[0;32m   2538\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2539\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\trainer.py:3715\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3713\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n\u001b[1;32m-> 3715\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3717\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\accelerate\\accelerator.py:2248\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[0;32m   2247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2248\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0ca8fc1-df28-484e-b43f-ca281c4a913b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6206094622612, 'eval_runtime': 4.4028, 'eval_samples_per_second': 2.271, 'eval_steps_per_second': 0.227, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate(test_data)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d5327ed-559f-4a5e-9a1b-20eab3fd5852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the necessary metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ef5223-8727-4574-9834-9ba3054273c5",
   "metadata": {},
   "source": [
    "# Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd501640-8ff0-4a9e-89ed-cf2d379b4aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3d251-b50f-4924-9716-baefa11c0c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401259b7-9f2c-4e75-9889-8eee2013d9a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "957c0323-0604-4698-bf57-a0b5c8af74e0",
   "metadata": {},
   "source": [
    "# Extrinsic Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da9d733-be20-4598-bb9c-198c6547bd7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
